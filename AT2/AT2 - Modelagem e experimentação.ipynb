{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33ed7cba-fc06-4dd3-a039-e28cf538d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: torch in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: torchvision in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: torch==2.7.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torchvision) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: filelock in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from torch==2.7.0->torchvision) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\n",
      "Requirement already satisfied: scikit-learn in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/hugo-henrique/miniconda3/envs/CaseIaAT2/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffa2a4f0-c96c-48ff-9201-2f38070f14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "\n",
    "# Função para limpar o campo 'image' no DataFrame\n",
    "def clean_img_name(name):\n",
    "    # Se for string no formato de lista (ex: \"['nome.jpg']\"), converte para lista e pega o primeiro item\n",
    "    if isinstance(name, str) and name.startswith('[') and name.endswith(']'):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(name)\n",
    "            if isinstance(parsed, list) and len(parsed) > 0:\n",
    "                return parsed[0]\n",
    "        except:\n",
    "            pass\n",
    "    return name\n",
    "\n",
    "# Carregar CSV e limpar nomes das imagens\n",
    "df = pd.read_csv('../dados/dataset_pose.csv')\n",
    "df['image'] = df['image'].apply(clean_img_name)\n",
    "\n",
    "# Converter DataFrame em lista de dicionários\n",
    "samples = df.to_dict(orient='records')\n",
    "\n",
    "# Mapear ações para índices\n",
    "actions = sorted(set(s['action'] for s in samples))\n",
    "action_to_idx = {a: i for i, a in enumerate(actions)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb4337c-ec1c-4b49-87bf-49a53b3fda42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn_pad(batch):\n",
    "    \"\"\"\n",
    "    batch: lista de tuplas (image, keypoints_tensor, label)\n",
    "    Faz padding dos keypoints para o tamanho do maior do batch.\n",
    "    \"\"\"\n",
    "    images = [item[0] for item in batch]\n",
    "    keypoints = [item[1] for item in batch]\n",
    "    labels = [item[2] for item in batch]\n",
    "    \n",
    "    # Empilha imagens normalmente (mesmo shape)\n",
    "    images = torch.stack(images)\n",
    "    \n",
    "    # Pega o tamanho máximo de keypoints no batch\n",
    "    max_kps = max(kp.shape[0] for kp in keypoints)\n",
    "    \n",
    "    # Padding dos keypoints com zeros\n",
    "    padded_kps = []\n",
    "    for kp in keypoints:\n",
    "        pad_size = max_kps - kp.shape[0]\n",
    "        if pad_size > 0:\n",
    "            padding = torch.zeros((pad_size, 3), dtype=torch.float32)\n",
    "            kp_padded = torch.cat([kp, padding], dim=0)\n",
    "        else:\n",
    "            kp_padded = kp\n",
    "        padded_kps.append(kp_padded)\n",
    "    \n",
    "    keypoints_batch = torch.stack(padded_kps)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return images, keypoints_batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f7d442b-4294-41af-8770-29fd920d7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseDataset(Dataset):\n",
    "    def __init__(self, data, images_dir, img_key='image', keypoints_key='keypoints', label_key='action',\n",
    "                 image_size=(256, 256), transform=None):\n",
    "     \n",
    "        self.data = data\n",
    "        self.images_dir = images_dir\n",
    "        self.img_key = img_key\n",
    "        self.keypoints_key = keypoints_key\n",
    "        self.label_key = label_key\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Se não passar transform, cria padrão de redimensionar e converter em tensor\n",
    "        if self.transform is None:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize(self.image_size),\n",
    "                T.ToTensor(),\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data[idx]\n",
    "    \n",
    "        img_filename = row[self.img_key]\n",
    "        if isinstance(img_filename, list):\n",
    "            img_filename = img_filename[0]\n",
    "        if isinstance(img_filename, str) and img_filename.startswith(\"[\") and img_filename.endswith(\"]\"):\n",
    "            img_filename = img_filename.strip(\"[]\").replace(\"'\", \"\").replace('\"', \"\").strip()\n",
    "    \n",
    "        img_path = os.path.join(self.images_dir, img_filename)\n",
    "    \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "    \n",
    "        keypoints = row[self.keypoints_key]\n",
    "    \n",
    "        if isinstance(keypoints, str):\n",
    "            keypoints = json.loads(keypoints)\n",
    "    \n",
    "        if isinstance(keypoints, list) and isinstance(keypoints[0], dict):\n",
    "            keypoints = [[kp['x'], kp['y']] for kp in keypoints]\n",
    "        keypoints = np.array(keypoints)\n",
    "        if keypoints.shape[1] == 2:\n",
    "            # Adiciona uma terceira coluna com 1 (visibilidade = 1, por exemplo)\n",
    "            vis = np.ones((keypoints.shape[0], 1))\n",
    "            keypoints = np.hstack((keypoints, vis))\n",
    "        keypoints = torch.tensor(keypoints, dtype=torch.float32)\n",
    "    \n",
    "        label = row[self.label_key]\n",
    "        \n",
    "        # Se label for string numérica\n",
    "        try:\n",
    "            label = int(label)\n",
    "        except:\n",
    "            # se for categoria textual, faça seu mapeamento aqui\n",
    "            label_map = {'dancing': 0, 'miscellaneous': 1, 'sports': 2}  # ajuste conforme seu caso\n",
    "            label = label_map[label]\n",
    "        \n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "\n",
    "        max_kps = 16\n",
    "        if keypoints.shape[0] < max_kps:\n",
    "            pad_size = max_kps - keypoints.shape[0]\n",
    "            padding = torch.zeros(pad_size, keypoints.shape[1])  # assume (N,3)\n",
    "            keypoints = torch.cat([keypoints, padding], dim=0)\n",
    "        elif keypoints.shape[0] > max_kps:\n",
    "            keypoints = keypoints[:max_kps]\n",
    "    \n",
    "        return image, keypoints, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d817a53-df1c-4809-9112-aaaa38c53cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Ler CSV\n",
    "df = pd.read_csv('../dados/dataset_pose.csv')\n",
    "\n",
    "# 2. Criar mapeamento das ações para índices\n",
    "actions = sorted(df['action'].unique())\n",
    "action_to_idx = {a: i for i, a in enumerate(actions)}\n",
    "\n",
    "# 3. Mapear coluna 'action' para numérico\n",
    "df['action_idx'] = df['action'].map(action_to_idx)  # Usa a coluna esperada pela classe\n",
    "\n",
    "# 4. Separar treino/val (80/20), estratificado pela label\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['action_idx'], random_state=42)\n",
    "\n",
    "# 5. Converter DataFrame para lista de dicts (records)\n",
    "train_samples = train_df.to_dict('records')\n",
    "val_samples = val_df.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc0d056-023c-4ec4-9088-d79cb1493310",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PoseDataset(train_samples, images_dir='../dados/mpii_human_pose_v1/images')\n",
    "val_dataset = PoseDataset(val_samples, images_dir='../dados/mpii_human_pose_v1/images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4302b554-e7fd-479c-8b26-3cd2deb7ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, collate_fn=collate_fn_pad)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, collate_fn=collate_fn_pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95d933-1101-41ab-a348-e6ebbde8b670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9308727-3bf0-4b85-9dd8-e25d09537600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04b3f3-fa6f-4205-873f-58f17af10742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2dafe8-87d9-4a63-b847-290cab7b449d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d35ff17c-e98d-496c-bf55-4bcdeced2be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def evaluate_model(model, dataloader, device, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    mse_loss = nn.MSELoss()\n",
    "    total_kp_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, keypoints, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            keypoints = keypoints[:, :, :2].reshape(images.size(0), -1).to(device)\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            pred_kps, pred_action = model(images)\n",
    "\n",
    "            # Regressão: acumula MSE dos keypoints\n",
    "            loss_kps = mse_loss(pred_kps, keypoints)\n",
    "            total_kp_loss += loss_kps.item()\n",
    "\n",
    "            # Classificação: coleta predições e labels para classification_report\n",
    "            preds = pred_action.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    avg_kp_loss = total_kp_loss / len(dataloader)\n",
    "    cls_report = classification_report(all_labels, all_preds, target_names=class_names, zero_division=0)\n",
    "\n",
    "    print(\"=== Classification Report ===\")\n",
    "    print(cls_report)\n",
    "    print(f\"Average Keypoints MSE Loss: {avg_kp_loss:.4f}\")\n",
    "\n",
    "    return cls_report, avg_kp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f918892b-2714-4682-8603-baab57df25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Classe modelo adaptada para filtro variável (parâmetro)\n",
    "class PoseActionCNN(nn.Module):\n",
    "    def __init__(self, num_keypoints=16, num_classes=3, base_filters=32):\n",
    "        super(PoseActionCNN, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, base_filters, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(base_filters, base_filters*2, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(base_filters*2, base_filters*4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((4, 4))  # reduz para (B, base_filters*4, 4, 4)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        fc_input_size = base_filters*4 * 4 * 4\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fc_input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.fc_keypoints = nn.Linear(512, num_keypoints * 2)\n",
    "        self.fc_action = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return self.fc_keypoints(x), self.fc_action(x)\n",
    "\n",
    "# Funções train_one_epoch e validate continuam iguais (copie a sua)\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, mse_loss, ce_loss, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, keypoints, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        keypoints = keypoints[:, :, :2].reshape(images.size(0), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        pred_kps, pred_action = model(images)\n",
    "\n",
    "        loss_kps = mse_loss(pred_kps, keypoints)\n",
    "        loss_action = ce_loss(pred_action, labels)\n",
    "        loss = loss_kps + loss_action\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, mse_loss, ce_loss, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, keypoints, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            keypoints = keypoints[:, :, :2].reshape(images.size(0), -1).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pred_kps, pred_action = model(images)\n",
    "\n",
    "            loss_kps = mse_loss(pred_kps, keypoints)\n",
    "            loss_action = ce_loss(pred_action, labels)\n",
    "            loss = loss_kps + loss_action\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = pred_action.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    return total_loss / len(dataloader), acc\n",
    "\n",
    "# --- Validação cruzada com busca em hiperparâmetros ---\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "def cross_validate(dataset, device, k=5, epochs=10, batch_size=32, param_grid=None):\n",
    "    from torch.utils.data import DataLoader, Subset\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    reports = []\n",
    "\n",
    "    # hiperparâmetros para grid search (exemplo)\n",
    "    if param_grid is None:\n",
    "        param_grid = [{'lr': 0.01, 'base_filters': 32}, {'lr': 0.1, 'base_filters': 64}]\n",
    "\n",
    "    for params in param_grid:\n",
    "        print(f\"\\nTestando parâmetros: lr={params['lr']}, base_filters={params['base_filters']}\")\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "            print(f\"\\nFold {fold+1}/{k}\")\n",
    "\n",
    "            train_subset = Subset(dataset, train_idx)\n",
    "            val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "            train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "            val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "            model = PoseActionCNN(base_filters=params['base_filters']).to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "            mse_loss = nn.MSELoss()\n",
    "            ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                train_loss = train_one_epoch(model, train_loader, optimizer, mse_loss, ce_loss, device)\n",
    "                val_loss, val_acc = validate(model, val_loader, mse_loss, ce_loss, device)\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "            # Adiciona relatório detalhado após todas as épocas do fold\n",
    "            print(f\"\\nClassification Report for Fold {fold+1}:\")\n",
    "            report, kp_mse = evaluate_model(model, val_loader, device, class_names=['dancing', 'miscellaneous', 'sports'])\n",
    "            reports.append({'classification_report': report, 'keypoints_mse': kp_mse})\n",
    "\n",
    "            fold_results.append({'params': params, 'val_loss': val_loss, 'val_acc': val_acc})\n",
    "\n",
    "    return fold_results, reports\n",
    "\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a867f05d-1afb-4aed-a8be-8004fafeb1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testando parâmetros: lr=0.01, base_filters=32\n",
      "\n",
      "Fold 1/4\n",
      "Epoch 1/5 - Val Loss: 107325.1875 | Val Acc: 0.2833\n",
      "Epoch 2/5 - Val Loss: 90662.0156 | Val Acc: 0.2833\n",
      "Epoch 3/5 - Val Loss: 88226.3490 | Val Acc: 0.3667\n",
      "Epoch 4/5 - Val Loss: 103864.2708 | Val Acc: 0.3500\n",
      "Epoch 5/5 - Val Loss: 88506.7799 | Val Acc: 0.3667\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.00      0.00      0.00        51\n",
      "miscellaneous       0.00      0.00      0.00        63\n",
      "       sports       0.37      1.00      0.54        66\n",
      "\n",
      "     accuracy                           0.37       180\n",
      "    macro avg       0.12      0.33      0.18       180\n",
      " weighted avg       0.13      0.37      0.20       180\n",
      "\n",
      "Average Keypoints MSE Loss: 88503.5690\n",
      "\n",
      "Fold 2/4\n",
      "Epoch 1/5 - Val Loss: 344597.3203 | Val Acc: 0.3611\n",
      "Epoch 2/5 - Val Loss: 87907.2142 | Val Acc: 0.3611\n",
      "Epoch 3/5 - Val Loss: 76998.0749 | Val Acc: 0.3778\n",
      "Epoch 4/5 - Val Loss: 79481.9232 | Val Acc: 0.3611\n",
      "Epoch 5/5 - Val Loss: 80858.2507 | Val Acc: 0.3778\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.38      1.00      0.55        68\n",
      "miscellaneous       0.00      0.00      0.00        47\n",
      "       sports       0.00      0.00      0.00        65\n",
      "\n",
      "     accuracy                           0.38       180\n",
      "    macro avg       0.13      0.33      0.18       180\n",
      " weighted avg       0.14      0.38      0.21       180\n",
      "\n",
      "Average Keypoints MSE Loss: 80853.4896\n",
      "\n",
      "Fold 3/4\n",
      "Epoch 1/5 - Val Loss: 318226.8516 | Val Acc: 0.3000\n",
      "Epoch 2/5 - Val Loss: 112320.3516 | Val Acc: 0.3000\n",
      "Epoch 3/5 - Val Loss: 82475.9115 | Val Acc: 0.3722\n",
      "Epoch 4/5 - Val Loss: 79809.4141 | Val Acc: 0.3000\n",
      "Epoch 5/5 - Val Loss: 79991.8125 | Val Acc: 0.3000\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.00      0.00      0.00        67\n",
      "miscellaneous       0.00      0.00      0.00        59\n",
      "       sports       0.30      1.00      0.46        54\n",
      "\n",
      "     accuracy                           0.30       180\n",
      "    macro avg       0.10      0.33      0.15       180\n",
      " weighted avg       0.09      0.30      0.14       180\n",
      "\n",
      "Average Keypoints MSE Loss: 79988.5365\n",
      "\n",
      "Fold 4/4\n",
      "Epoch 1/5 - Val Loss: 355961.9974 | Val Acc: 0.3056\n",
      "Epoch 2/5 - Val Loss: 319890.2786 | Val Acc: 0.3000\n",
      "Epoch 3/5 - Val Loss: 95456.9512 | Val Acc: 0.3000\n",
      "Epoch 4/5 - Val Loss: 83607.5293 | Val Acc: 0.3944\n",
      "Epoch 5/5 - Val Loss: 81879.4023 | Val Acc: 0.3000\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.30      1.00      0.46        54\n",
      "miscellaneous       0.00      0.00      0.00        71\n",
      "       sports       0.00      0.00      0.00        55\n",
      "\n",
      "     accuracy                           0.30       180\n",
      "    macro avg       0.10      0.33      0.15       180\n",
      " weighted avg       0.09      0.30      0.14       180\n",
      "\n",
      "Average Keypoints MSE Loss: 81878.2201\n",
      "\n",
      "Testando parâmetros: lr=0.1, base_filters=64\n",
      "\n",
      "Fold 1/4\n",
      "Epoch 1/5 - Val Loss: 380702.8021 | Val Acc: 0.3667\n",
      "Epoch 2/5 - Val Loss: 340498.9427 | Val Acc: 0.2833\n",
      "Epoch 3/5 - Val Loss: 255472.2370 | Val Acc: 0.3667\n",
      "Epoch 4/5 - Val Loss: 162799.8411 | Val Acc: 0.3667\n",
      "Epoch 5/5 - Val Loss: 108536.0404 | Val Acc: 0.3667\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.00      0.00      0.00        51\n",
      "miscellaneous       0.00      0.00      0.00        63\n",
      "       sports       0.37      1.00      0.54        66\n",
      "\n",
      "     accuracy                           0.37       180\n",
      "    macro avg       0.12      0.33      0.18       180\n",
      " weighted avg       0.13      0.37      0.20       180\n",
      "\n",
      "Average Keypoints MSE Loss: 108534.9258\n",
      "\n",
      "Fold 2/4\n",
      "Epoch 1/5 - Val Loss: 318590.6693 | Val Acc: 0.3778\n",
      "Epoch 2/5 - Val Loss: 119326.4974 | Val Acc: 0.2611\n",
      "Epoch 3/5 - Val Loss: 80435.9818 | Val Acc: 0.3778\n",
      "Epoch 4/5 - Val Loss: 72737.7539 | Val Acc: 0.2611\n",
      "Epoch 5/5 - Val Loss: 73989.6361 | Val Acc: 0.2611\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.00      0.00      0.00        68\n",
      "miscellaneous       0.26      1.00      0.41        47\n",
      "       sports       0.00      0.00      0.00        65\n",
      "\n",
      "     accuracy                           0.26       180\n",
      "    macro avg       0.09      0.33      0.14       180\n",
      " weighted avg       0.07      0.26      0.11       180\n",
      "\n",
      "Average Keypoints MSE Loss: 73977.7539\n",
      "\n",
      "Fold 3/4\n",
      "Epoch 1/5 - Val Loss: 3153487.7500 | Val Acc: 0.2944\n",
      "Epoch 2/5 - Val Loss: 592773.2188 | Val Acc: 0.3000\n",
      "Epoch 3/5 - Val Loss: 93915.8255 | Val Acc: 0.3000\n",
      "Epoch 4/5 - Val Loss: 156478.5299 | Val Acc: 0.3722\n",
      "Epoch 5/5 - Val Loss: 95060.5065 | Val Acc: 0.3722\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.37      1.00      0.54        67\n",
      "miscellaneous       0.00      0.00      0.00        59\n",
      "       sports       0.00      0.00      0.00        54\n",
      "\n",
      "     accuracy                           0.37       180\n",
      "    macro avg       0.12      0.33      0.18       180\n",
      " weighted avg       0.14      0.37      0.20       180\n",
      "\n",
      "Average Keypoints MSE Loss: 95031.1628\n",
      "\n",
      "Fold 4/4\n",
      "Epoch 1/5 - Val Loss: 299870.0156 | Val Acc: 0.3000\n",
      "Epoch 2/5 - Val Loss: 83565.9062 | Val Acc: 0.3944\n",
      "Epoch 3/5 - Val Loss: 87692.6328 | Val Acc: 0.3056\n",
      "Epoch 4/5 - Val Loss: 84689.7155 | Val Acc: 0.3000\n",
      "Epoch 5/5 - Val Loss: 81389.6048 | Val Acc: 0.3000\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.30      1.00      0.46        54\n",
      "miscellaneous       0.00      0.00      0.00        71\n",
      "       sports       0.00      0.00      0.00        55\n",
      "\n",
      "     accuracy                           0.30       180\n",
      "    macro avg       0.10      0.33      0.15       180\n",
      " weighted avg       0.09      0.30      0.14       180\n",
      "\n",
      "Average Keypoints MSE Loss: 81373.6875\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "results, reports = cross_validate(train_dataset, device=device, k=4, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbbf1a2c-2489-49c3-99d2-aa0f1310383d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'lr': 0.01, 'base_filters': 32},\n",
       "  'val_loss': 88506.77994791667,\n",
       "  'val_acc': 0.36666666666666664},\n",
       " {'params': {'lr': 0.01, 'base_filters': 32},\n",
       "  'val_loss': 80858.25065104167,\n",
       "  'val_acc': 0.37777777777777777},\n",
       " {'params': {'lr': 0.01, 'base_filters': 32},\n",
       "  'val_loss': 79991.8125,\n",
       "  'val_acc': 0.3},\n",
       " {'params': {'lr': 0.01, 'base_filters': 32},\n",
       "  'val_loss': 81879.40234375,\n",
       "  'val_acc': 0.3},\n",
       " {'params': {'lr': 0.1, 'base_filters': 64},\n",
       "  'val_loss': 108536.04036458333,\n",
       "  'val_acc': 0.36666666666666664},\n",
       " {'params': {'lr': 0.1, 'base_filters': 64},\n",
       "  'val_loss': 73989.63606770833,\n",
       "  'val_acc': 0.2611111111111111},\n",
       " {'params': {'lr': 0.1, 'base_filters': 64},\n",
       "  'val_loss': 95060.50651041667,\n",
       "  'val_acc': 0.37222222222222223},\n",
       " {'params': {'lr': 0.1, 'base_filters': 64},\n",
       "  'val_loss': 81389.60481770833,\n",
       "  'val_acc': 0.3}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cefaacb5-c1d1-441b-9b7c-94b751457656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'classification_report': '               precision    recall  f1-score   support\\n\\n      dancing       0.00      0.00      0.00        51\\nmiscellaneous       0.00      0.00      0.00        63\\n       sports       0.37      1.00      0.54        66\\n\\n     accuracy                           0.37       180\\n    macro avg       0.12      0.33      0.18       180\\n weighted avg       0.13      0.37      0.20       180\\n',\n",
       "  'keypoints_mse': 88503.56901041667},\n",
       " {'classification_report': '               precision    recall  f1-score   support\\n\\n      dancing       0.38      1.00      0.55        68\\nmiscellaneous       0.00      0.00      0.00        47\\n       sports       0.00      0.00      0.00        65\\n\\n     accuracy                           0.38       180\\n    macro avg       0.13      0.33      0.18       180\\n weighted avg       0.14      0.38      0.21       180\\n',\n",
       "  'keypoints_mse': 80853.48958333333},\n",
       " {'classification_report': '               precision    recall  f1-score   support\\n\\n      dancing       0.00      0.00      0.00        67\\nmiscellaneous       0.00      0.00      0.00        59\\n       sports       0.30      1.00      0.46        54\\n\\n     accuracy                           0.30       180\\n    macro avg       0.10      0.33      0.15       180\\n weighted avg       0.09      0.30      0.14       180\\n',\n",
       "  'keypoints_mse': 79988.53645833333},\n",
       " {'classification_report': '               precision    recall  f1-score   support\\n\\n      dancing       0.30      1.00      0.46        54\\nmiscellaneous       0.00      0.00      0.00        71\\n       sports       0.00      0.00      0.00        55\\n\\n     accuracy                           0.30       180\\n    macro avg       0.10      0.33      0.15       180\\n weighted avg       0.09      0.30      0.14       180\\n',\n",
       "  'keypoints_mse': 81878.22005208333},\n",
       " {'classification_report': '               precision    recall  f1-score   support\\n\\n      dancing       0.00      0.00      0.00        51\\nmiscellaneous       0.00      0.00      0.00        63\\n       sports       0.37      1.00      0.54        66\\n\\n     accuracy                           0.37       180\\n    macro avg       0.12      0.33      0.18       180\\n weighted avg       0.13      0.37      0.20       180\\n',\n",
       "  'keypoints_mse': 108534.92578125},\n",
       " {'classification_report': '               precision    recall  f1-score   support\\n\\n      dancing       0.00      0.00      0.00        68\\nmiscellaneous       0.26      1.00      0.41        47\\n       sports       0.00      0.00      0.00        65\\n\\n     accuracy                           0.26       180\\n    macro avg       0.09      0.33      0.14       180\\n weighted avg       0.07      0.26      0.11       180\\n',\n",
       "  'keypoints_mse': 73977.75390625},\n",
       " {'classification_report': '               precision    recall  f1-score   support\\n\\n      dancing       0.37      1.00      0.54        67\\nmiscellaneous       0.00      0.00      0.00        59\\n       sports       0.00      0.00      0.00        54\\n\\n     accuracy                           0.37       180\\n    macro avg       0.12      0.33      0.18       180\\n weighted avg       0.14      0.37      0.20       180\\n',\n",
       "  'keypoints_mse': 95031.16276041667},\n",
       " {'classification_report': '               precision    recall  f1-score   support\\n\\n      dancing       0.30      1.00      0.46        54\\nmiscellaneous       0.00      0.00      0.00        71\\n       sports       0.00      0.00      0.00        55\\n\\n     accuracy                           0.30       180\\n    macro avg       0.10      0.33      0.15       180\\n weighted avg       0.09      0.30      0.14       180\\n',\n",
       "  'keypoints_mse': 81373.6875}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "656c6db4-47d2-4062-a744-3f5584b15502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOInspiredNet(nn.Module):\n",
    "    def __init__(self, num_keypoints=16, num_classes=3):\n",
    "        super(YOLOInspiredNet, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),  # (B, 16, H, W)\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),  # (B, 16, H/2, W/2)\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),  # (B, 32, H/4, W/4)\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),  # (B, 64, H/8, W/8)\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.AdaptiveAvgPool2d((4, 4))  # (B, 128, 4, 4)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.fc_keypoints = nn.Linear(512, num_keypoints * 2)  # regressão\n",
    "        self.fc_class = nn.Linear(512, num_classes)            # classificação\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return self.fc_keypoints(x), self.fc_class(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb9dd685-9d3e-4bfb-8330-93210f2ad384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate2(dataset, device, k=5, epochs=10, batch_size=32, param_grid=None):\n",
    "    from torch.utils.data import DataLoader, Subset\n",
    "    from sklearn.model_selection import KFold\n",
    "    from collections import Counter\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    reports = []\n",
    "\n",
    "    if param_grid is None:\n",
    "        param_grid = [{'lr': 0.01, 'base_filters': 32}, {'lr': 0.1, 'base_filters': 64}]\n",
    "\n",
    "    for params in param_grid:\n",
    "        print(f\"\\nTestando parâmetros: lr={params['lr']}, base_filters={params['base_filters']}\")\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "            print(f\"\\nFold {fold+1}/{k}\")\n",
    "\n",
    "            train_subset = Subset(dataset, train_idx)\n",
    "            val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "            train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "            val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "            model = YOLOInspiredNet(num_keypoints=16, num_classes=3).to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "            mse_loss = nn.MSELoss()\n",
    "\n",
    "            # === CALCULAR PESOS DAS CLASSES PARA ESSE FOLD ===\n",
    "            train_labels = [dataset[i][2] for i in train_idx]  # Ajuste se o label estiver em outra posição\n",
    "            label_counts = Counter(train_labels)\n",
    "            total = sum(label_counts.values())\n",
    "            num_classes = 3\n",
    "            weights = [total / label_counts.get(i, 1) for i in range(num_classes)]\n",
    "            weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "            ce_loss = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "            print(f\"Pesos usados para CrossEntropyLoss: {weights.tolist()}\")\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                train_loss = train_one_epoch(model, train_loader, optimizer, mse_loss, ce_loss, device,\n",
    "                                             loss_weights=(0.5, 1.0))  # Ponderação das losses\n",
    "                val_loss, val_acc = validate(model, val_loader, mse_loss, ce_loss, device)\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "                # Diagnóstico de colapso: distribuição de classes previstas\n",
    "                if epoch == epochs - 1:\n",
    "                    with torch.no_grad():\n",
    "                        all_preds = []\n",
    "                        for images, _, _ in val_loader:\n",
    "                            images = images.to(device)\n",
    "                            logits = model(images)[1]\n",
    "                            preds = torch.argmax(logits, dim=1)\n",
    "                            all_preds.extend(preds.cpu().numpy())\n",
    "                        pred_dist = Counter(all_preds)\n",
    "                        print(f\"Distribuição das classes previstas: {pred_dist}\")\n",
    "\n",
    "            print(f\"\\nClassification Report for Fold {fold+1}:\")\n",
    "            report, kp_mse = evaluate_model(model, val_loader, device, class_names=['dancing', 'miscellaneous', 'sports'])\n",
    "            reports.append({'classification_report': report, 'keypoints_mse': kp_mse})\n",
    "\n",
    "            fold_results.append({'params': params, 'val_loss': val_loss, 'val_acc': val_acc})\n",
    "\n",
    "    return fold_results, reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62901975-6c71-4ceb-bcb3-603eec539182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testando parâmetros: lr=0.01, base_filters=32\n",
      "\n",
      "Fold 1/4\n",
      "Epoch 1/5 - Val Loss: 378660.2292 | Val Acc: 0.3833\n",
      "Epoch 2/5 - Val Loss: 297631.9036 | Val Acc: 0.3667\n",
      "Epoch 3/5 - Val Loss: 104242.2344 | Val Acc: 0.3500\n",
      "Epoch 4/5 - Val Loss: 96989.0951 | Val Acc: 0.3500\n",
      "Epoch 5/5 - Val Loss: 87297.4089 | Val Acc: 0.3667\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.00      0.00      0.00        51\n",
      "miscellaneous       0.00      0.00      0.00        63\n",
      "       sports       0.37      1.00      0.54        66\n",
      "\n",
      "     accuracy                           0.37       180\n",
      "    macro avg       0.12      0.33      0.18       180\n",
      " weighted avg       0.13      0.37      0.20       180\n",
      "\n",
      "Average Keypoints MSE Loss: 87293.6914\n",
      "\n",
      "Fold 2/4\n",
      "Epoch 1/5 - Val Loss: 345028.8333 | Val Acc: 0.2611\n",
      "Epoch 2/5 - Val Loss: 111414.1979 | Val Acc: 0.3611\n",
      "Epoch 3/5 - Val Loss: 78089.7884 | Val Acc: 0.3778\n",
      "Epoch 4/5 - Val Loss: 74540.5911 | Val Acc: 0.3611\n",
      "Epoch 5/5 - Val Loss: 74720.1849 | Val Acc: 0.3778\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.38      1.00      0.55        68\n",
      "miscellaneous       0.00      0.00      0.00        47\n",
      "       sports       0.00      0.00      0.00        65\n",
      "\n",
      "     accuracy                           0.38       180\n",
      "    macro avg       0.13      0.33      0.18       180\n",
      " weighted avg       0.14      0.38      0.21       180\n",
      "\n",
      "Average Keypoints MSE Loss: 74718.4635\n",
      "\n",
      "Fold 3/4\n",
      "Epoch 1/5 - Val Loss: 146625.4128 | Val Acc: 0.3722\n",
      "Epoch 2/5 - Val Loss: 86759.3620 | Val Acc: 0.3722\n",
      "Epoch 3/5 - Val Loss: 86363.9479 | Val Acc: 0.3278\n",
      "Epoch 4/5 - Val Loss: 91458.6432 | Val Acc: 0.3000\n",
      "Epoch 5/5 - Val Loss: 93066.1680 | Val Acc: 0.3278\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.00      0.00      0.00        67\n",
      "miscellaneous       0.33      1.00      0.49        59\n",
      "       sports       0.00      0.00      0.00        54\n",
      "\n",
      "     accuracy                           0.33       180\n",
      "    macro avg       0.11      0.33      0.16       180\n",
      " weighted avg       0.11      0.33      0.16       180\n",
      "\n",
      "Average Keypoints MSE Loss: 93061.6654\n",
      "\n",
      "Fold 4/4\n",
      "Epoch 1/5 - Val Loss: 335721.7344 | Val Acc: 0.3944\n",
      "Epoch 2/5 - Val Loss: 93765.4466 | Val Acc: 0.2889\n",
      "Epoch 3/5 - Val Loss: 91557.7637 | Val Acc: 0.3000\n",
      "Epoch 4/5 - Val Loss: 80576.3340 | Val Acc: 0.3000\n",
      "Epoch 5/5 - Val Loss: 81235.3053 | Val Acc: 0.3000\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.30      1.00      0.46        54\n",
      "miscellaneous       0.00      0.00      0.00        71\n",
      "       sports       0.00      0.00      0.00        55\n",
      "\n",
      "     accuracy                           0.30       180\n",
      "    macro avg       0.10      0.33      0.15       180\n",
      " weighted avg       0.09      0.30      0.14       180\n",
      "\n",
      "Average Keypoints MSE Loss: 81230.2669\n",
      "\n",
      "Testando parâmetros: lr=0.1, base_filters=64\n",
      "\n",
      "Fold 1/4\n",
      "Epoch 1/5 - Val Loss: 124761.7174 | Val Acc: 0.3500\n",
      "Epoch 2/5 - Val Loss: 92776.5964 | Val Acc: 0.3500\n",
      "Epoch 3/5 - Val Loss: 90183.1719 | Val Acc: 0.3500\n",
      "Epoch 4/5 - Val Loss: 87589.3268 | Val Acc: 0.3500\n",
      "Epoch 5/5 - Val Loss: 90691.3698 | Val Acc: 0.3667\n",
      "\n",
      "Classification Report for Fold 1:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.00      0.00      0.00        51\n",
      "miscellaneous       0.00      0.00      0.00        63\n",
      "       sports       0.37      1.00      0.54        66\n",
      "\n",
      "     accuracy                           0.37       180\n",
      "    macro avg       0.12      0.33      0.18       180\n",
      " weighted avg       0.13      0.37      0.20       180\n",
      "\n",
      "Average Keypoints MSE Loss: 90644.2005\n",
      "\n",
      "Fold 2/4\n",
      "Epoch 1/5 - Val Loss: 151561.1120 | Val Acc: 0.2611\n",
      "Epoch 2/5 - Val Loss: 337372.4896 | Val Acc: 0.3778\n",
      "Epoch 3/5 - Val Loss: 293736.1406 | Val Acc: 0.3611\n",
      "Epoch 4/5 - Val Loss: 133610.3854 | Val Acc: 0.2611\n",
      "Epoch 5/5 - Val Loss: 84794.6979 | Val Acc: 0.2611\n",
      "\n",
      "Classification Report for Fold 2:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.00      0.00      0.00        68\n",
      "miscellaneous       0.26      1.00      0.41        47\n",
      "       sports       0.00      0.00      0.00        65\n",
      "\n",
      "     accuracy                           0.26       180\n",
      "    macro avg       0.09      0.33      0.14       180\n",
      " weighted avg       0.07      0.26      0.11       180\n",
      "\n",
      "Average Keypoints MSE Loss: 84784.8047\n",
      "\n",
      "Fold 3/4\n",
      "Epoch 1/5 - Val Loss: 324709.3177 | Val Acc: 0.3000\n",
      "Epoch 2/5 - Val Loss: 315671.7578 | Val Acc: 0.3722\n",
      "Epoch 3/5 - Val Loss: 288366.8229 | Val Acc: 0.3722\n",
      "Epoch 4/5 - Val Loss: 239282.8724 | Val Acc: 0.3722\n",
      "Epoch 5/5 - Val Loss: 180806.9453 | Val Acc: 0.3722\n",
      "\n",
      "Classification Report for Fold 3:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.37      1.00      0.54        67\n",
      "miscellaneous       0.00      0.00      0.00        59\n",
      "       sports       0.00      0.00      0.00        54\n",
      "\n",
      "     accuracy                           0.37       180\n",
      "    macro avg       0.12      0.33      0.18       180\n",
      " weighted avg       0.14      0.37      0.20       180\n",
      "\n",
      "Average Keypoints MSE Loss: 180804.9557\n",
      "\n",
      "Fold 4/4\n",
      "Epoch 1/5 - Val Loss: 424486.0521 | Val Acc: 0.3000\n",
      "Epoch 2/5 - Val Loss: 255191.6302 | Val Acc: 0.3000\n",
      "Epoch 3/5 - Val Loss: 270082.3724 | Val Acc: 0.3056\n",
      "Epoch 4/5 - Val Loss: 83006.2663 | Val Acc: 0.3056\n",
      "Epoch 5/5 - Val Loss: 100255.9147 | Val Acc: 0.3056\n",
      "\n",
      "Classification Report for Fold 4:\n",
      "=== Classification Report ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      dancing       0.00      0.00      0.00        54\n",
      "miscellaneous       0.00      0.00      0.00        71\n",
      "       sports       0.31      1.00      0.47        55\n",
      "\n",
      "     accuracy                           0.31       180\n",
      "    macro avg       0.10      0.33      0.16       180\n",
      " weighted avg       0.09      0.31      0.14       180\n",
      "\n",
      "Average Keypoints MSE Loss: 100226.1562\n"
     ]
    }
   ],
   "source": [
    "results2, reports2 = cross_validate(train_dataset, device=device, k=4, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649bcd64-121d-4bc8-a5f5-a21878c92183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
